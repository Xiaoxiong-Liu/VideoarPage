<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>VideoAR Gallery</title>
  <link rel="stylesheet" href="./static/css/video-grid.css" />
</head>

<body>
  <header class="hero">
    <h1 class="title">VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction</h1>
    <p class="authors">
        Longbin Ji &nbsp;·&nbsp; Xiaoxiong Liu &nbsp;·&nbsp; Junyuan Shang &nbsp;·&nbsp;
        Shuohuan Wang &nbsp;·&nbsp; Yu Sun &nbsp;·&nbsp; Hua Wu &nbsp;·&nbsp; Haifeng Wang
      </p>
      <p class="authors">
        ERNIE Team, Baidu
      </p>
    
      <!-- <p class="subtitle">Hover or touch to play</p> -->
    
      <div class="abstract">
        <h3>Abstract</h3>
        <p>
          Recent advances in video generation have been dominated by diffusion and flow-matching models,
          which produce high-quality results but remain computationally intensive and difficult to scale.
          In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for
          video generation that combines multi-scale next-frame prediction with autoregressive modeling.
          VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with
          causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes
          spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE,
          Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation
          and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial
          and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves
          new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6
          while reducing inference steps by over 10x, and reaching a VBench score of 81.74—competitive with
          diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows
          the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient,
          and temporally consistent foundation for future video generation research.
        </p>
      </div>
    </header>
    <!-- <p class="subtitle">Hover or touch to play</p>
    <p class="subtitle">Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.</p> -->
  </header>

  <h2 class="section-title">VideoAR-Pro Gallery</h2>
  <h2 class="subtitle">VideoAR-Pro is a preliminary internal prototype built upon VideoAR, exploring unified video-audio AR generation.</h2>

  <section class="gallery gallery-eb5" id="gallery-eb5"></section>

  <h2 class="section-title">VideoAR-4B Gallery</h2>
  <section class="gallery gallery-videoar" id="gallery-videoar"></section>

  <script src="./static/js/video-grid.js"></script>
</body>
</html>